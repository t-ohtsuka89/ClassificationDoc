seed: 123

log:
  filename: train.log

dataset:
  text_dir: data/texts
  label_dir: data/label_level1
  batch_size: 8

method: TransformerCNN

trainer:
  max_epochs: 100

model:
  emb_size: 256
  out_channels: 256
  nhead: 2
  hidden_dim: 256
  nlayers: 2
  drop_rate: 0.2
  optimizer: RAdam
  learning_rate: 1.0e-3
  T_max: 100

early_stopping:
  monitor: val_f1
  mode: max
  patience: 20
