seed: 123

log_path: config/transformer/summary/level1-v1.log
save_dir: ./models/checkpoints/transformer/level1-v1
save_top_k: 1
prefix: transformer

dataset:
  data_module: MyDataModule
  text_dir: data/summary
  label_dir: data/label_level1
  batch_size: 16

method: TransformerClassifier
add_special_token: true

trainer:
  max_epochs: -1
  min_epochs: 200
  accumulate_grad_batches: 2

model:
  mode: special_token
  emb_size: 256
  nhead: 2
  nlayers: 2
  hidden_dim: 512
  drop_rate: 0.25
  optimizer: Ranger
  learning_rate: 2.0e-3
  T_max: null

early_stopping:
  monitor: val_f1
  mode: min
  patience: 20
