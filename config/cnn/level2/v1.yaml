seed: 123

log:
  filename: train.log

dataset:
  text_dir: data/texts
  label_dir: data/label_level2

train:
  batch_size: 64
  n_epoch: 100

model:
  emb_size: 256
  out_channels: 200
  drop_rate: 0.1
  optimizer: RAdam
  learning_rate: 1.0e-2
  T_max: 100

early_stopping:
  monitor: val_f1
  mode: max
  patience: 20
